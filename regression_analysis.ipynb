{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4981, 7393)\n",
      "   Geno_Code  pop   m1   m2   m3   m4   m5   m6   m7   m8  ...  m7382  m7383  \\\n",
      "0  Z001E0001  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...    0.0    0.0   \n",
      "1  Z001E0002  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  ...    2.0    2.0   \n",
      "2  Z001E0003  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
      "3  Z001E0004  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    2.0    2.0   \n",
      "4  Z001E0005  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  ...    0.0    0.0   \n",
      "\n",
      "   m7384  m7385  m7386  m7387  m7388  m7389  Entry     DtoA  \n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  75.5364  \n",
      "1    2.0    2.0    2.0    2.0    2.0    2.0    2.0  76.9075  \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    3.0  75.2646  \n",
      "3    2.0    2.0    2.0    2.0    2.0    2.0    4.0  73.6933  \n",
      "4    0.0    0.0    0.0    0.0    0.0    0.0    5.0  79.2441  \n",
      "\n",
      "[5 rows x 7393 columns]\n",
      "Saved to maize_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# === Load SAS file ===\n",
    "df, meta = pyreadstat.read_sas7bdat('maize-1.sas7bdat')\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# === Save to CSV (optional) ===\n",
    "df.to_csv('maize_data.csv', index=False)\n",
    "print(\"Saved to maize_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# === Load data ===\n",
    "df = pd.read_csv(\"maize_data.csv\")\n",
    "\n",
    "# === Prepare features and target ===\n",
    "X = df.drop('DtoA', axis=1)\n",
    "y = df['DtoA']\n",
    "\n",
    "# Convert categorical (string) columns to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# # Standardize data for Ridge and SVR\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# === Custom RMSE scorer ===\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "# === Function to create pipeline ===\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "# === Reusable GridSearch function using CV (RMSE only) ===\n",
    "def run_grid_search(model_pipeline, param_grid, X_train, y_train, X_test, y_test, cv=5):\n",
    "    \"\"\"\n",
    "    Run GridSearchCV with cross-validation on training data, evaluate on test set.\n",
    "    Only uses RMSE as the scoring metric.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=rmse_scorer,\n",
    "        refit=True,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Fit GridSearch\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # CV metrics (mean of training CV folds)\n",
    "    cv_results = grid_search.cv_results_\n",
    "    mean_rmse = np.sqrt(-cv_results['mean_test_score'][grid_search.best_index_])\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(f\"CV RMSE (train): {mean_rmse:.4f}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best params: {'regressor__alpha': 100.0}\n",
      "CV RMSE (train): 1.8732\n",
      "Test RMSE: 3.4956\n",
      "Time: 156.79 s\n"
     ]
    }
   ],
   "source": [
    "# Ridge example\n",
    "ridge_pipeline = create_pipeline(Ridge())\n",
    "ridge_param_grid = {'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "start_time = time.time()\n",
    "best_ridge, best_params = run_grid_search(\n",
    "    ridge_pipeline, ridge_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time: {elapsed_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best params: {'regressor__alpha': 0.1}\n",
      "CV RMSE (train): 1.8533\n",
      "Test RMSE: 3.3932\n",
      "Time: 546.18 s\n"
     ]
    }
   ],
   "source": [
    "# === Lasso example ===\n",
    "lasso_pipeline = create_pipeline(Lasso(max_iter=5000))\n",
    "lasso_param_grid = {'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "start_time = time.time()\n",
    "best_lasso, test_rmse_lasso = run_grid_search(\n",
    "    lasso_pipeline, lasso_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time: {elapsed_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Best params: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.5}\n",
      "CV RMSE (train): 1.8527\n",
      "Test RMSE: 3.3981\n"
     ]
    }
   ],
   "source": [
    "# === ElasticNet example ===\n",
    "elastic_pipeline = create_pipeline(ElasticNet(max_iter=5000))\n",
    "elastic_param_grid = {\n",
    "    'regressor__alpha': [0.001, 0.01, 0.1, 1.0],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "best_elastic, test_rmse_elastic = run_grid_search(\n",
    "    elastic_pipeline, elastic_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Time: {elapsed_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC/BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Best params: {}\n",
      "CV RMSE (train): 1.8636\n",
      "Test RMSE: 3.4311\n",
      "\n",
      "=== Stepwise (Forward BIC) Results ===\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     67\u001b[39m elapsed_time = time.time() - start_time\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Stepwise (Forward BIC) Results ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRMSE (CV): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstepwise_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRMSE_CV\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRMSE (Test): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstepwise_metrics[\u001b[33m'\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m# Feats/Comps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(best_stepwise.named_steps[\u001b[33m'\u001b[39m\u001b[33mstepwise\u001b[39m\u001b[33m'\u001b[39m].best_subset_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# === Forward Stepwise BIC Selector ===\n",
    "class ForwardStepwiseBIC(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.best_subset_ = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        remaining_features = list(range(n_features))\n",
    "        selected_features = []\n",
    "        best_bic = np.inf\n",
    "\n",
    "        while remaining_features:\n",
    "            improved = False\n",
    "            best_feature = None\n",
    "\n",
    "            for f in remaining_features:\n",
    "                trial_features = selected_features + [f]\n",
    "                X_sub = X[:, trial_features]\n",
    "                lr = LinearRegression().fit(X_sub, y)\n",
    "                rss = np.sum((y - lr.predict(X_sub))**2)\n",
    "                bic = n_samples * np.log(rss / n_samples) + (len(trial_features)+1) * np.log(n_samples)\n",
    "\n",
    "                if bic < best_bic:\n",
    "                    best_bic = bic\n",
    "                    best_feature = f\n",
    "                    improved = True\n",
    "\n",
    "            if improved:\n",
    "                selected_features.append(best_feature)\n",
    "                remaining_features.remove(best_feature)\n",
    "            else:\n",
    "                break  # Stop if no improvement\n",
    "\n",
    "        self.best_subset_ = selected_features\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.best_subset_]\n",
    "\n",
    "# === Stepwise (BIC) Pipeline ===\n",
    "stepwise_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('stepwise', ForwardStepwiseBIC()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# No hyperparameters to grid search\n",
    "stepwise_param_grid = {}\n",
    "\n",
    "# === Run pipeline with timing ===\n",
    "start_time = time.time()\n",
    "best_stepwise, stepwise_metrics = run_grid_search(\n",
    "    stepwise_pipeline, stepwise_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"# Feats/Comps: {len(best_stepwise.named_steps['stepwise'].best_subset_)}\")\n",
    "print(f\"Time: {elapsed_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best params: {'pca__n_components': 50}\n",
      "CV RMSE (train): 1.8930\n",
      "Test RMSE: 3.5666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# === PCR (Principal Components Regression) ===\n",
    "pcr_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pcr_param_grid = {\n",
    "    'pca__n_components': [5, 10, 20, 50, 100]  # tune number of components\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "best_pcr, pcr_metrics = run_grid_search(\n",
    "    pcr_pipeline, pcr_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "Best params: {'pls__n_components': 20}\n",
      "CV RMSE (train): 1.8715\n",
      "Test RMSE: 3.4961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# === PLS Regression ===\n",
    "pls_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pls', PLSRegression())\n",
    "])\n",
    "\n",
    "pls_param_grid = {\n",
    "    'pls__n_components': [5, 10, 20, 50, 100]  # tune number of PLS components\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "best_pls, pls_metrics = run_grid_search(\n",
    "    pls_pipeline, pls_param_grid,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    cv=10\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
